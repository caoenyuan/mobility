{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a8afe9-1f35-48de-8384-6063d350cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340eccc8-60ac-4b8c-9807-dcbbc86185e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcf602d95054bd8897e8c5e0d438b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6195080505c4b019460f8f47606697f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce494fbdb9fb4e6eae6c02862d8e7787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fab605aebc7497f90ac2c75841aba83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4905a4dec24a2aa7f01f51e82d8e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc812b358e447f3a4d2456c9bee4d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55236c89a76649ebb82ba696a6151928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c9969f80fc47f5a4e88eeae88ee347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41fb42b9fd4408aa4236b4dfc79ea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34e6da4ca6e4e23b656eea9d93ddc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3771f7c2b5a4d18910e13be56fd78a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d247af1941b84e1fb981ac743ccbbf09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             #load_in_8bit=True,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8460fd-afb2-4fe1-aff2-5178d4634515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          关键词                                               连接.1  \\\n",
      "0       eVTOL  https://weibo.com/1659280190/NzRLNoI5S?refer_f...   \n",
      "1       eVTOL  https://weibo.com/5320254069/NzRwy85RE?refer_f...   \n",
      "2       eVTOL  https://weibo.com/6906214710/NzR06AnSg?refer_f...   \n",
      "3       eVTOL  https://weibo.com/2245266941/NzPGsDD9m?refer_f...   \n",
      "4       eVTOL  https://weibo.com/1988518703/NzPGsvWgj?refer_f...   \n",
      "...       ...                                                ...   \n",
      "128015   vtol  https://twitter.com/EugeneGuy14/status/1741316...   \n",
      "128016   vtol  https://twitter.com/Kastro44_/status/174130862...   \n",
      "128017   vtol  https://twitter.com/SmestarZ/status/1741300400...   \n",
      "128018   vtol  https://twitter.com/KaleiSplatoon/status/17412...   \n",
      "128019   vtol  https://twitter.com/Throwplate/status/17412491...   \n",
      "\n",
      "                   博主名 verified_type         nation  year  \\\n",
      "0       QuantHedgeFund            --          china  2024   \n",
      "1                 潘哥悟市            --          china  2024   \n",
      "2                 投资者张            --          china  2024   \n",
      "3                 数码头条      Business          china  2024   \n",
      "4                 冲浪新知      Business          china  2024   \n",
      "...                ...           ...            ...   ...   \n",
      "128015        1.47E+18            --  united states  2023   \n",
      "128016        1.12E+18            --        unknown  2023   \n",
      "128017      3266742241            --        unknown  2023   \n",
      "128018        1.61E+18            --        unknown  2023   \n",
      "128019        1.05E+18            --        unknown  2023   \n",
      "\n",
      "                                             cleaned_text  \n",
      "0       深圳市低空融合飞行示范区eVTOL首飞测试完成1月1日讯，据深圳发布微信公众号消息，近日，“...  \n",
      "1       据深圳发布，近日，“深圳市低空融合飞行示范区eVTOL首飞测试”在大梅沙滨海公交场站完成。厚...  \n",
      "2                                 深圳市低空融合飞行示范区eVTOL首飞测试完成  \n",
      "3       深圳市低空融合飞行示范区 eVTOL 首飞测试完成据深圳发布，近日，“深圳市低空融合飞行示范...  \n",
      "4       深圳市低空融合飞行示范区 eVTOL 首飞测试完成据深圳发布，近日，“深圳市低空融合飞行示范...  \n",
      "...                                                   ...  \n",
      "128015                                     Due got a vtol  \n",
      "128016   Loving the comparison to \"VTOL VR's stubborne...  \n",
      "128017     It is fact that LM had hired Yak team as te...  \n",
      "128018   This guy is shitting on my two favourite VR g...  \n",
      "128019   VTOL technology for efficient landing on the ...  \n",
      "\n",
      "[128020 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train_tw = pd.read_csv('weibo_twitter_2024_text.csv', encoding = 'utf-8-sig')\n",
    "print(data_train_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b790d90-b981-4f46-a18c-946ae79ce683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         https://weibo.com/1659280190/NzRLNoI5S?refer_f...\n",
       "1         https://weibo.com/5320254069/NzRwy85RE?refer_f...\n",
       "2         https://weibo.com/6906214710/NzR06AnSg?refer_f...\n",
       "3         https://weibo.com/2245266941/NzPGsDD9m?refer_f...\n",
       "4         https://weibo.com/1988518703/NzPGsvWgj?refer_f...\n",
       "                                ...                        \n",
       "128015    https://twitter.com/EugeneGuy14/status/1741316...\n",
       "128016    https://twitter.com/Kastro44_/status/174130862...\n",
       "128017    https://twitter.com/SmestarZ/status/1741300400...\n",
       "128018    https://twitter.com/KaleiSplatoon/status/17412...\n",
       "128019    https://twitter.com/Throwplate/status/17412491...\n",
       "Name: 连接.1, Length: 128020, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_train_tw['cleaned_text'] = data_train_tw['Title'] + data_train_tw['Abstract']\n",
    "data_train_tw['连接.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c9cbec-df86-4fc4-9d82-d42e983354b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a helpful AI assistant that answers questions briefly and directly.<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|> The following texts are research or tweets about urban low-altitude transportation. Rank the attitude as positive, negative, or neutral, and categorize the discussion content into one of the following categories: \n",
      "1: Safety \n",
      "2: Aerodynamics \n",
      "3: Integration and Infrastructure \n",
      "4: Automation \n",
      "5: Price and cost \n",
      "6: Policy \n",
      "7: User experience \n",
      "Only answer the attitude and category number, don't answer anything else. For example: Positive, 5\n",
      "Text: 据深圳发布，近日，“深圳市低空融合飞行示范区eVTOL首飞测试”在大梅沙滨海公交场站完成。厚为华圣公司现场展示了EH216-S型无人驾驶载人飞行器绕场飞行。该飞行器已取得中国民航局颁发的型号合格证和标准适航证，成为全球首个获得适航证的eVTOL。 <|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(content):\n",
    "    begin = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\"\n",
    "    #syst = \"<<SYS>> You are a helpful AI assistant that answers questions briefly and directly.\\n If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>\\n\"\n",
    "    #inst = \"Read the following text. Does it mention the Gilbert damping constant of a certain material? If so, list the corresponding material and its Gilbert damping canstant.\\n\" + content\n",
    "    syst = \"You are a helpful AI assistant that answers questions briefly and directly.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\"\n",
    "    inst = \"The following texts are research or tweets about urban low-altitude transportation. Rank the attitude as positive, negative, or neutral, and categorize the discussion content into one of the following categories: \\n1: Safety \\n2: Aerodynamics \\n3: Integration and Infrastructure \\n4: Automation \\n5: Price and cost \\n6: Policy \\n7: User experience \\nOnly answer the attitude and category number, don't answer anything else. For example: Positive, 5\\nText: \"+content\n",
    "    end = \"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    prompt = (\" \").join([begin, syst, inst, end])\n",
    "    return prompt\n",
    "\n",
    "#print(generate_prompt('How are you?'))\n",
    "#print(generate_prompt(data_train['text_cleaned'][1]))\n",
    "print(generate_prompt(data_train_tw['cleaned_text'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10bf3c-2959-4697-abe3-0a010973c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存到 output.csv，当前迭代次数：199，用时：93.20 秒\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "data = []\n",
    "save_interval = 200\n",
    "\n",
    "start_time = time.time()  # 记录开始时间\n",
    "\n",
    "for i in range(len(data_train_tw)):#['text_cleaned']):\n",
    "    if i % 1 == 0:\n",
    "        #if pd.isna(data_train_tw.iloc[i]['result']) and not pd.isna(data_train_tw.iloc[i]['cleaned_text']):\n",
    "        if not pd.isna(data_train_tw.iloc[i]['cleaned_text']):\n",
    "            #print(i)\n",
    "            \n",
    "            input_prompt = generate_prompt(data_train_tw.iloc[i]['cleaned_text'])\n",
    "            #input_tokens = tokenizer(input_prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "            #inputs = tokenizer(input_prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "            inputs = tokenizer(input_prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "            input_tokens = inputs[\"input_ids\"]\n",
    "            attention_mask = inputs[\"attention_mask\"]\n",
    "            with torch.cuda.amp.autocast():\n",
    "                generation_output = model.generate(\n",
    "                    input_ids=input_tokens,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=8,\n",
    "                    do_sample=False,\n",
    "                    repetition_penalty=1.1,\n",
    "                    num_return_sequences=1,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "            op = tokenizer.decode(generation_output[0], skip_special_tokens=True)\n",
    "            #print(op)\n",
    "\n",
    "            inst_index = op.find('assistant\\n')\n",
    "        \n",
    "            if inst_index != -1:\n",
    "                #print(text)\n",
    "                #print(op[inst_index + len('assistant\\n'):])\n",
    "                data.append({\"number\": i, \"link\": data_train_tw.iloc[i]['连接.1'], \"text\": data_train_tw.iloc[i]['cleaned_text'], \"result\": op[inst_index + len('assistant\\n'):].replace('\\n', ' ')})\n",
    "                #data.append({\"number\": i, \"link\": data_train_tw.iloc[i]['Title'], \"text\": data_train_tw.iloc[i]['Abstract'], \"result\": op[inst_index + len('assistant\\n'):].replace('\\n', ' ')})\n",
    "            else:\n",
    "                print(\"未找到'assistant\\n'标记\")\n",
    "                #data.append({\"number\": i, \"text\": text, \"sentiment\":\"\"})\n",
    "    \n",
    "            # 每 save_interval 个迭代保存一次\n",
    "            if len(data) == save_interval:\n",
    "                df = pd.DataFrame(data)\n",
    "                df.to_csv(\"output_tw.csv\", encoding = 'utf-8-sig', index=False, mode='a', header=False)  # 追加模式\n",
    "                data = []\n",
    "                end_time = time.time()  # 记录结束时间\n",
    "                elapsed_time = end_time - start_time  # 计算用时\n",
    "                print(f\"已保存到 output.csv，当前迭代次数：{i}，用时：{elapsed_time:.2f} 秒\")\n",
    "        \n",
    "                start_time = end_time  # 更新开始时间，用于计算下一个周期的用时\n",
    "\n",
    "# 最后一次保存\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"output_tw.csv\", encoding = 'utf-8-sig', index=False, mode='a', header=False)\n",
    "print(\"已保存到 output_tw.csv\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1acd7-c2b8-4a22-a35c-fcbd94f52eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da8769-d9ae-4f0d-a139-75efcfac928b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab5041-cf07-49a1-a238-311ed4a779ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc8124-802f-4ba9-8507-5cb34e7ee4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
